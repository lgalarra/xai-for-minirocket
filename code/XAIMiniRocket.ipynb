{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471af97f-13ba-4755-b4e4-9f48af1f9fd9",
   "metadata": {},
   "source": [
    "## XAIMINIROCKET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b651ec-2aa6-44d7-877b-947255e37ab0",
   "metadata": {},
   "source": [
    "### Bloque 1\n",
    "Carga las librerías usadas en todo el flujo y recarga el módulo minirocket_multivariate_variable por si se lo edita recientemente."
   ]
  },
  {
   "cell_type": "code",
   "id": "60255519-8f94-46ea-a44e-1713994400a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T08:36:03.068419Z",
     "start_time": "2025-09-01T08:36:02.309418Z"
    }
   },
   "source": [
    "import importlib, os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import minirocket_multivariate_variable as mmv\n",
    "importlib.reload(mmv)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import shap\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgalarra/Documents/git/xai-for-minirocket/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e1215ce5-d4a3-4769-8e4d-fdee88e8934d",
   "metadata": {},
   "source": [
    "### Bloque 2\n",
    "Define parámetros globales del experimento.\n",
    "\n",
    "#### Entradas:\n",
    "\n",
    "DATA_PATH → aquí se indica la ruta al juego de datos (archivo Parquet).\n",
    "Ejemplos: \"./data/mi_dataset.parquet\" o \"C:/proyecto/df.parquet\".\n",
    "\n",
    "LABEL_COL → nombre exacto de la columna de etiquetas en el parquet.\n",
    "\n",
    "TEST_SIZE y RANDOM_STATE se pueden dejar por defecto.\n",
    "\n",
    "#### Salidas: \n",
    "variables de configuración disponibles para los bloques siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05676055-ab10-4ac2-81a8-455986ff6928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape DF: (240, 7875)\n",
      "Mapa etiqueta: {'FACIL': 0, 'DIFICIL': 1}\n",
      "X: (240, 1, 7874) | y: (240,)\n",
      "X_train: (192, 1, 7874) | X_test: (48, 1, 7874) | clases: [0 1]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"df_V.parquet\"       \n",
    "LABEL_COL = \"RealDifficulty\"\n",
    "TEST_SIZE = 0.20\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "print(\"Shape DF:\", df.shape)\n",
    "\n",
    "\n",
    "label_raw = (\n",
    "    df[LABEL_COL].astype(str).str.strip().str.lower()\n",
    "      .str.replace(\"í\",\"i\", regex=False)\n",
    "      .str.replace(\"á\",\"a\", regex=False)\n",
    ")\n",
    "\n",
    "mapping_text2id = {\"facil\":0, \"dificil\":1}\n",
    "unknown = sorted(set(label_raw.unique()) - set(mapping_text2id.keys()))\n",
    "if unknown:\n",
    "    raise ValueError(f\"Valores inesperados en {LABEL_COL}: {unknown}\")\n",
    "\n",
    "y = label_raw.map(mapping_text2id).to_numpy(dtype=int)\n",
    "print(\"Mapa etiqueta:\", {\"FACIL\":0, \"DIFICIL\":1})\n",
    "\n",
    "\n",
    "X2D = df.drop(columns=[LABEL_COL]).to_numpy(dtype=np.float32)\n",
    "n, L = X2D.shape\n",
    "X = X2D.reshape(n, 1, L)    # (n, C=1, L)\n",
    "print(\"X:\", X.shape, \"| y:\", y.shape)\n",
    "\n",
    "cnt = Counter(y)\n",
    "strat = y if min(cnt.values()) >= 2 else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=strat\n",
    ")\n",
    "print(\"X_train:\", X_train.shape, \"| X_test:\", X_test.shape, \"| clases:\", np.unique(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af90606-d78d-4a6c-9bcd-ece6737f8ef9",
   "metadata": {},
   "source": [
    "\n",
    "### Bloque 3\n",
    "\n",
    "Ajusta MiniRocket exclusivamente con X_train, aprendiendo dilataciones, sesgos y selección de canales. Estos parámetros quedan guardados internamente en mmv (estado global).\n",
    "\n",
    "Transforma X_train a ϕ, devolviendo: Phi_train (n_train × F), la matriz de firmas PPV que se usará para entrenar la LR.\n",
    "\n",
    "out_train[\"traces\"], metadatos por firma (σ por tiempo, taps κ, dilatación, canales, sesgo), necesarios luego para la atribución temporal β(t).\n",
    "\n",
    "Finalmente imprime la forma de Phi_train.\n",
    "\n",
    "#### Entradas requeridas:\n",
    "\n",
    "X_train con forma (n_train, C, L), preparado en bloques previos.\n",
    "\n",
    "#### Salidas/efectos:\n",
    "\n",
    "Estado interno de MiniRocket actualizado.\n",
    "\n",
    "Phi_train listo para el bloque de LR(ϕ); traces disponibles para explicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81689001-ae51-4074-b507-d792d6b6b687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_train: (192, 9996)\n"
     ]
    }
   ],
   "source": [
    "mmv.fit_minirocket_parameters(X_train)\n",
    "out_train = mmv.transform_prime(X_train)  \n",
    "Phi_train = out_train[\"phi\"]               \n",
    "print(\"Phi_train:\", Phi_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b445cad-4296-46d7-8235-07296616feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador LR(ϕ) entrenado.\n",
      "model_logit conectado (vía ϕ).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_phi = make_pipeline(\n",
    "    StandardScaler(with_mean=False),\n",
    "    LogisticRegression(max_iter=2000, solver=\"lbfgs\", multi_class=\"auto\", n_jobs=-1)\n",
    ").fit(Phi_train, y_train)\n",
    "print(\"Clasificador LR(ϕ) entrenado.\")\n",
    "\n",
    "# 3.2) Conectar el clasificador para mmv.model_logit (vía ϕ)\n",
    "mmv.set_phi_classifier_for_logits(clf_phi)\n",
    "print(\"model_logit conectado (vía ϕ).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dee7ff-1f3d-4d5a-84b8-73f51eda0a38",
   "metadata": {},
   "source": [
    "### Bloque 4\n",
    "\n",
    "##### 1. Construye un background en el espacio ϕ (MiniRocket) a partir de TRAIN\n",
    "\n",
    "Toma una muestra aleatoria de bg_size = min(128, len(X_train)) instancias de X_train (semilla fija para reproducibilidad).\n",
    "\n",
    "Aplica mmv.transform_prime a cada instancia y apila sus firmas ϕ en phi_background (B × F).\n",
    "\n",
    "Este background se usa para:\n",
    "\n",
    "SHAP LinearExplainer (como referencia de distribución en ϕ).\n",
    "\n",
    "Obtener la media en ϕ escalado: phi_bg_scaled = scaler.transform(phi_background), y su media mu_bg_scaled.\n",
    "\n",
    "##### 2. Extrae el scaler y el clasificador lr desde el pipeline\n",
    "\n",
    "scaler = clf_phi.named_steps[\"standardscaler\"] permite escalar cualquier ϕ.\n",
    "\n",
    "lr = clf_phi.named_steps[\"logisticregression\"] expone los pesos/coeficientes del modelo en ϕ.\n",
    "\n",
    "Calcula phi_bg_scaled y su media mu_bg_scaled (vector de tamaño F).\n",
    "\n",
    "##### 3. Define helpers para baseline por medoide\n",
    "\n",
    "_ensure_TC y _flatten_tc: aseguran y aplanan la forma temporal–canal para cálculos intermedios.\n",
    "\n",
    "compute_medoids_by_class: para cada clase, selecciona el medoide (ejemplo más representativo) evaluando distancias en un subconjunto (máx. 300) para eficiencia.\n",
    "\n",
    "pick_opposite_medoid: dada una instancia x_raw, predice su clase en ϕ y devuelve el medoide de la clase opuesta (baseline de referencia x̄), con fallback si falta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8abd16-f084-45cf-ac4f-2dc028e365c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ϕ(background): 100%|██████████| 128/128 [01:04<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_background: (128, 9996)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rng = np.random.default_rng(42)\n",
    "bg_size = min(128, len(X_train))\n",
    "idx_bg = rng.choice(len(X_train), size=bg_size, replace=False)\n",
    "\n",
    "phi_background = np.vstack([ mmv.transform_prime(X_train[k:k+1])[\"phi\"]\n",
    "                             for k in tqdm(idx_bg, desc=\"ϕ(background)\") ])\n",
    "print(\"phi_background:\", phi_background.shape)\n",
    "\n",
    "# 4.2) Extraer scaler y LR del pipeline\n",
    "scaler = clf_phi.named_steps[\"standardscaler\"]\n",
    "lr     = clf_phi.named_steps[\"logisticregression\"]\n",
    "\n",
    "phi_bg_scaled = scaler.transform(phi_background)   # (B, F)\n",
    "mu_bg_scaled  = phi_bg_scaled.mean(axis=0)         # media background en espacio escalado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785f6ac9-c452-492d-b797-bc076a043cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_TC(x):\n",
    "    x = np.asarray(x)\n",
    "    if x.ndim == 3:\n",
    "        assert x.shape[0] == 1\n",
    "        x = x[0]\n",
    "    if x.ndim == 2:\n",
    "        return x.T if x.shape[0] < x.shape[1] else x\n",
    "    raise ValueError(f\"Forma no soportada: {x.shape}\")\n",
    "\n",
    "def _flatten_tc(x_tc):\n",
    "    return _ensure_TC(x_tc).reshape(-1)\n",
    "\n",
    "def compute_medoids_by_class(X_src, y_src, max_candidates=300, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    med = {}\n",
    "    for cls in np.unique(y_src):\n",
    "        Xc = X_src[y_src == cls]\n",
    "        m = len(Xc)\n",
    "        if m == 0:\n",
    "            continue\n",
    "        idx = np.arange(m)\n",
    "        if m > max_candidates:\n",
    "            idx = rng.choice(m, size=max_candidates, replace=False)\n",
    "        flat = np.vstack([_flatten_tc(Xc[i:i+1][0].T) for i in idx]).astype(np.float32)\n",
    "        norms = (flat**2).sum(1, keepdims=True)\n",
    "        D2 = norms + norms.T - 2.0 * flat @ flat.T\n",
    "        np.maximum(D2, 0.0, out=D2)\n",
    "        D = np.sqrt(D2, dtype=np.float32)\n",
    "        best_local = int(np.argmin(D.mean(1)))\n",
    "        med[int(cls)] = Xc[idx[best_local]:idx[best_local]+1]\n",
    "    return med\n",
    "\n",
    "def pick_opposite_medoid(x_raw, clf_phi, medoids, transform_prime):\n",
    "    phi_x = transform_prime(x_raw)[\"phi\"]\n",
    "    proba = clf_phi.predict_proba(phi_x)[0]\n",
    "    clf_classes = clf_phi.classes_ if hasattr(clf_phi, \"classes_\") else np.arange(len(proba))\n",
    "    order = np.argsort(-proba)\n",
    "    y_hat_cls = int(clf_classes[order[0]])\n",
    "    # Devuelve el medoid de la clase más probable NO elegida\n",
    "    for j in order[1:]:\n",
    "        cand = int(clf_classes[j])\n",
    "        if cand in medoids:\n",
    "            return medoids[cand], cand\n",
    "    # fallback\n",
    "    for cand in medoids:\n",
    "        if cand != y_hat_cls:\n",
    "            return medoids[cand], cand\n",
    "    raise RuntimeError(\"No hay medoid opuesto disponible.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e780e-da6a-46e9-9ca0-2e01b91868cb",
   "metadata": {},
   "source": [
    "### Bloque 5\n",
    "\n",
    "Se alcula, en el conjunto bas, el medoide por clase (ejemplo más representativo).\n",
    "\n",
    "Selecciona una instancia de prueba i para explicar.\n",
    "\n",
    "Define la referencia (baseline) x̄ como el medoid de la clase opuesta a la predicción del modelo en ϕ para esa instancia.\n",
    "\n",
    "Transforma x y x̄ al espacio de firmas ϕ y obtiene sus trazas (σ por tiempo, kernel κ, dilatación, etc.), necesarias para atribución temporal.\n",
    "\n",
    "Convierte ambas series a forma temporal–canal (T, C) y calcula los logits f(x) y f(x̄), obteniendo Δf = f(x) − f(x̄), la cantidad total que deben explicar las atribuciones β(t).\n",
    "\n",
    "##### Entradas requeridas:\n",
    "\n",
    "X_train, y_train, X_test, y_test ya construidos; clf_phi entrenado y conectado con mmv.set_phi_classifier_for_logits(clf_phi); MiniRocket ajustado previamente.\n",
    "\n",
    "##### Salidas principales:\n",
    "\n",
    "X0_op (baseline por medoid opuesto) y su clase cls_opp.\n",
    "\n",
    "phi_x, phi_x0 y sus traces, traces0.\n",
    "\n",
    "fx, fx0 y delta_f (escala logit), que luego se usará para verificar cierre local (Σβ ≈ Δf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8281d83a-9235-44d0-a072-1d9918ad6cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inst 0] y_true=0  |  baseline=medoid clase opuesta -> 1\n"
     ]
    }
   ],
   "source": [
    "X_base, y_base = X_train, y_train\n",
    "medoids = compute_medoids_by_class(X_base, y_base, max_candidates=300)\n",
    "\n",
    "i = 0\n",
    "x_raw  = X_test[i:i+1]       \n",
    "y_true = int(y_test[i])\n",
    "\n",
    "X0_op, cls_opp = pick_opposite_medoid(x_raw, clf_phi, medoids, mmv.transform_prime)\n",
    "print(f\"[inst {i}] y_true={y_true}  |  baseline=medoid clase opuesta -> {cls_opp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c53d9ff-d6f1-476f-98aa-e1f0d1256a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fx=0.196147  fx0=4.060584  Δf=-3.864437\n"
     ]
    }
   ],
   "source": [
    "out_x   = mmv.transform_prime(x_raw)\n",
    "out_x0  = mmv.transform_prime(X0_op)\n",
    "phi_x   = out_x[\"phi\"]\n",
    "phi_x0  = out_x0[\"phi\"]\n",
    "traces  = out_x[\"traces\"]   \n",
    "traces0 = out_x0[\"traces\"]  \n",
    "\n",
    "x_tc  = x_raw[0].T    # (T, C)\n",
    "x0_tc = X0_op[0].T\n",
    "fx  = float(mmv.model_logit(x_tc))\n",
    "fx0 = float(mmv.model_logit(x0_tc))\n",
    "delta_f = fx - fx0\n",
    "print(f\"fx={fx:.6f}  fx0={fx0:.6f}  Δf={delta_f:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe8d17-3f23-40b1-b5ab-68840697bb59",
   "metadata": {},
   "source": [
    "### Bloque 6\n",
    "\n",
    "Se estandariza las firmas ϕ de la instancia objetivo y de su referencia (baseline) usando el scaler del pipeline, para trabajar en el mismo espacio donde fue entrenada la LR. Luego identifica la clase objetivo (la que el modelo predice para la instancia) y toma el vector de pesos w_c de la regresión logística asociado a esa clase. Con eso calcula los α “brutos” en ϕ escalado mediante la forma cerrada de la LR: cada α_k mide la contribución del feature k como diferencia respecto a la media del background (μ en ϕ escalado) ponderada por w_c. A continuación calibra esos α para que suman exactamente Δf (la diferencia de logits entre la instancia y su baseline), garantizando local accuracy en el espacio de firmas. Después extrae la compuerta de referencia σ̄ por feature a partir de las traces del baseline y construye Δσ = σ − σ̄, un término ternario en {−1, 0, 1} que indica, para cada sello temporal y firma, si la activación cambió, no cambió o cambió en sentido opuesto entre la instancia y la referencia. Con los α calibrados y Δσ, propaga las contribuciones al tiempo mediante el operador de atribución: reparte cada α_k sobre los tiempos donde hay Δσ≠0, ponderando por los taps del kernel (patrón fijo 3×+2 y 6×−1) y por la dilatación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb79529-35a7-4ecb-a0bb-06c2da7f50f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∑α: -3.864436809354663  | Δf: -3.8644368093546633\n"
     ]
    }
   ],
   "source": [
    "phi_x_scaled  = scaler.transform(phi_x)\n",
    "phi_x0_scaled = scaler.transform(phi_x0)\n",
    "\n",
    "proba   = clf_phi.predict_proba(phi_x)[0]\n",
    "cls_idx = int(np.argmax(proba))\n",
    "W = lr.coef_                  # (n_classes, F) o (1, F)\n",
    "if W.ndim == 2 and W.shape[0] > 1:\n",
    "    w_c = W[cls_idx]\n",
    "else:\n",
    "    w = W.ravel()\n",
    "    w_c = w if cls_idx == 1 else -w\n",
    "\n",
    "alphas_raw = (phi_x_scaled[0] - mu_bg_scaled) * w_c\n",
    "\n",
    "alphas = mmv.calibrate_alphas_to_delta_f(alphas_raw, delta_f, phi_x_scaled, phi_x0_scaled)\n",
    "print(\"∑α:\", float(np.sum(alphas)), \" | Δf:\", float(delta_f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff14c05-ee93-4010-b726-5a84de57579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "β shape: (7874, 1)  Σβ: -3.864436809354662  error: 1.3322676295501878e-15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sigma_ref = [tr0[\"sigma\"] for tr0 in traces0]   \n",
    "\n",
    "beta = mmv.propagate_luis(alphas, traces, x_tc, x0_tc, sigma_ref=sigma_ref, mode=\"channel_energy\")\n",
    "print(\"β shape:\", beta.shape, \" Σβ:\", float(beta.sum()), \" error:\", float(beta.sum()-delta_f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b0c7f8-b8cb-471c-ad82-4208d2de653f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Local accuracy] Δf=-3.86443680935  Σβ=-3.86443680935  error=1.33e-15\n",
      "k=0 taps -> {-1.0: 6, 2.0: 3}\n",
      "k=1 taps -> {-1.0: 6, 2.0: 3}\n",
      "k=2 taps -> {-1.0: 6, 2.0: 3}\n",
      "k=123 taps -> {-1.0: 6, 2.0: 3}\n",
      "k=456 taps -> {-1.0: 6, 2.0: 3}\n",
      "k=999 taps -> {-1.0: 6, 2.0: 3}\n",
      "phi_x.shape: (1, 9996) | len(traces): 9996\n",
      "Δσ en {-1,0,1}: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "err = float(beta.sum() - delta_f)\n",
    "print(f\"[Local accuracy] Δf={delta_f:.12g}  Σβ={beta.sum():.12g}  error={err:.2e}\")\n",
    "\n",
    "for k in [0, 1, 2, 123, 456, 999]:\n",
    "    kappa = out_x[\"traces\"][k][\"kernel\"]\n",
    "    vals, counts = np.unique(kappa, return_counts=True)\n",
    "    print(f\"k={k} taps ->\", dict(zip(vals, counts)))\n",
    "print(\"phi_x.shape:\", phi_x.shape, \"| len(traces):\", len(traces))\n",
    "\n",
    "\n",
    "ok_delta_sigma = all(set(np.unique(tr[\"sigma\"] - tr0[\"sigma\"])) <= {-1,0,1}\n",
    "                     for tr,tr0 in zip(traces, traces0))\n",
    "print(\"Δσ en {-1,0,1}:\", ok_delta_sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b6ad6-1702-4099-b95b-f18e6e3c888e",
   "metadata": {},
   "source": [
    "### Bloque 7\n",
    "\n",
    "Este bloque construye un pipeline completo para cargar datos, entrenar MiniRocket + LR(ϕ) y, para un conjunto elegido (TEST o ALL), exportar:\n",
    "\n",
    "las atribuciones temporales β(t) por instancia,\n",
    "\n",
    "los α de SHAP en ϕ (tanto raw como calibrados a Δf),\n",
    "\n",
    "y un CSV de métricas de cierre (∑β vs Δf).\n",
    "\n",
    "A continuación, qué hace cada sección:\n",
    "\n",
    "#### 1. Configuración\n",
    "Define parámetros editables:\n",
    "\n",
    "DATA_PATH: ruta del juego de datos (Parquet). Aquí debe apuntar Luis a su archivo.\n",
    "\n",
    "LABEL_COL: nombre de la columna de etiqueta en el Parquet.\n",
    "\n",
    "RUN_SCOPE: qué dividir exportar (\"test\" o \"all\").\n",
    "\n",
    "BASELINE_FROM: de dónde tomar los medoides para la baseline (\"train\" o \"all\").\n",
    "\n",
    "OUT_DIR: carpeta donde se guardan los artefactos.\n",
    "\n",
    "#### 2. Carga y preparación de datos\n",
    "Lee el Parquet (DATA_PATH), normaliza la etiqueta FACIL/DIFICIL → 0/1, construye X con forma (n, 1, L) (todas las columnas excepto la etiqueta) y parte en X_train/X_test (estratificado cuando es posible).\n",
    "\n",
    "#### 3. MiniRocket + LR(ϕ)\n",
    "\n",
    "Ajusta los parámetros de MiniRocket solo con TRAIN.\n",
    "\n",
    "Transforma X_train a ϕ (Phi_train).\n",
    "\n",
    "Entrena una Logistic Regression sobre ϕ y la conecta para poder pedir logits desde la serie cruda.\n",
    "\n",
    "#### 4. Background para SHAP en ϕ escalado\n",
    "Muestrea un subconjunto de TRAIN, lo transforma a ϕ, lo escala con el scaler del pipeline y crea phi_bg_scaled, que se usa como background del explicador SHAP. (También se obtiene scaler y lr del pipeline.)\n",
    "\n",
    "#### 5. Explainer SHAP\n",
    "Crea un LinearExplainer sobre la LR usando phi_bg_scaled como background.\n",
    "\n",
    "#### 6. Helpers y baseline por medoide opuesto\n",
    "Define utilidades para:\n",
    "\n",
    "calcular medoides por clase (ejemplo más representativo),\n",
    "\n",
    "y elegir, para cada instancia, como baseline el medoid de la clase opuesta a la predicción del modelo en ϕ.\n",
    "\n",
    "#### 7. Fuente de medoids\n",
    "Construye los medoids desde TRAIN o ALL según BASELINE_FROM.\n",
    "\n",
    "#### 8. Selección del split a exportar\n",
    "Decide si iterar sobre TEST o ALL según RUN_SCOPE. Ajusta una etiqueta split_tag para nombrar los archivos de salida.\n",
    "\n",
    "#### 9. Preasignación de archivos de salida (memmap)\n",
    "Detecta dimensiones:\n",
    "\n",
    "F (nº de firmas ϕ),\n",
    "\n",
    "T (longitud temporal),\n",
    "\n",
    "N (nº de instancias a exportar),\n",
    "y preasigna tres archivos memmap (eficientes en RAM):\n",
    "\n",
    "betas_<split>.mmap → β(t) de tamaño (N, T),\n",
    "\n",
    "alphas_shap_raw_<split>.mmap → α SHAP raw (N, F),\n",
    "\n",
    "alphas_shap_cal_<split>.mmap → α SHAP calibrados (N, F).\n",
    "\n",
    "#### 10 Bucle principal por instancia (exportación)\n",
    "Para cada instancia del split elegido:\n",
    "\n",
    "Selecciona la baseline = medoid opuesto.\n",
    "\n",
    "Calcula Δf = logit(x) − logit(x̄).\n",
    "\n",
    "Obtiene ϕ y traces de x y x̄; escala ϕ.\n",
    "\n",
    "Calcula α SHAP en ϕ escalado con el explainer.\n",
    "\n",
    "Calibra α SHAP para que ∑α = Δf (local accuracy en ϕ).\n",
    "\n",
    "Propaga los α calibrados al tiempo con propagate_luis (usa Δσ ∈ {−1,0,1}, taps κ y dilatación) para obtener β(t) cumpliendo ∑β = Δf.\n",
    "\n",
    "Guarda β(t), α SHAP raw y α SHAP calibrados en los memmaps, y añade una fila de resumen (Δf, ∑α, ∑β, error, clase del medoid usado).\n",
    "\n",
    "#### 11. Cierre y resumen\n",
    "Sincroniza (cierra) los memmaps y escribe efficiency_<split>.csv con métricas por instancia, incluida rel_error = |Σβ − Δf| / |Δf|. Imprime un resumen de los archivos generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0d52904-6f5b-4547-939c-bdea392bb40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exportando (SHAP only) [test]: 100%|██████████| 48/48 [07:22<00:00,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo. Exportado en 'method1_outputs':\n",
      "  - betas_test.mmap         (β; shape=(48,7874))\n",
      "  - alphas_shap_raw_test.mmap   (α SHAP raw; shape=(48,9996))\n",
      "  - alphas_shap_cal_test.mmap    (α SHAP calibrados; shape=(48,9996))\n",
      "  - efficiency_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "DATA_PATH     = \"df_V.parquet\"\n",
    "LABEL_COL     = \"RealDifficulty\"\n",
    "TEST_SIZE     = 0.20\n",
    "RANDOM_STATE  = 42\n",
    "\n",
    "RUN_SCOPE     = \"all\"    # \"test\" | \"all\"\n",
    "BASELINE_FROM = \"all\"   # \"train\" | \"all\"\n",
    "OUT_DIR       = \"method1_outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "label_raw = (df[LABEL_COL].astype(str).str.strip().str.lower()\n",
    "             .str.replace(\"í\",\"i\", regex=False)\n",
    "             .str.replace(\"á\",\"a\", regex=False))\n",
    "mapping_text2id = {\"facil\":0, \"dificil\":1}\n",
    "y = label_raw.map(mapping_text2id).to_numpy(dtype=int)\n",
    "\n",
    "X2D = df.drop(columns=[LABEL_COL]).to_numpy(dtype=np.float32)\n",
    "X = X2D.reshape(len(X2D), 1, X2D.shape[1])  # (n, C=1, L)\n",
    "\n",
    "strat = y if np.min(np.bincount(y)) >= 2 else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=strat\n",
    ")\n",
    "\n",
    "\n",
    "mmv.fit_minirocket_parameters(X_train)\n",
    "Phi_train = mmv.transform_prime(X_train)[\"phi\"]\n",
    "\n",
    "clf_phi = make_pipeline(\n",
    "    StandardScaler(with_mean=False),\n",
    "    LogisticRegression(max_iter=2000, solver=\"lbfgs\", multi_class=\"auto\", n_jobs=-1)\n",
    ").fit(Phi_train, y_train)\n",
    "mmv.set_phi_classifier_for_logits(clf_phi)\n",
    "\n",
    "scaler = clf_phi.named_steps[\"standardscaler\"]\n",
    "lr     = clf_phi.named_steps[\"logisticregression\"]\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "bg_size = min(128, len(X_train))\n",
    "idx_bg = rng.choice(len(X_train), size=bg_size, replace=False)\n",
    "phi_background = np.vstack([ mmv.transform_prime(X_train[k:k+1])[\"phi\"] for k in idx_bg ])\n",
    "phi_bg_scaled  = scaler.transform(phi_background)\n",
    "\n",
    "try:\n",
    "    explainer = shap.LinearExplainer(lr, phi_bg_scaled)\n",
    "except Exception:\n",
    "    explainer = shap.explainers.Linear(lr, phi_bg_scaled)\n",
    "\n",
    "\n",
    "def _ensure_TC(x):\n",
    "    x = np.asarray(x)\n",
    "    if x.ndim == 3:  \n",
    "        assert x.shape[0] == 1\n",
    "        x = x[0]\n",
    "    return x.T if x.shape[0] < x.shape[1] else x\n",
    "\n",
    "def _flatten_tc(x_tc):\n",
    "    return _ensure_TC(x_tc).reshape(-1)\n",
    "\n",
    "def compute_medoids_by_class(X_src, y_src, max_candidates=300, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    med = {}\n",
    "    for cls in np.unique(y_src):\n",
    "        Xc = X_src[y_src == cls]\n",
    "        if len(Xc) == 0: \n",
    "            continue\n",
    "        idx = np.arange(len(Xc))\n",
    "        if len(Xc) > max_candidates:\n",
    "            idx = rng.choice(len(Xc), size=max_candidates, replace=False)\n",
    "        flat = np.vstack([_flatten_tc(Xc[i:i+1][0].T) for i in idx]).astype(np.float32)\n",
    "        norms = (flat**2).sum(1, keepdims=True)\n",
    "        D2 = norms + norms.T - 2.0 * flat @ flat.T\n",
    "        np.maximum(D2, 0.0, out=D2)\n",
    "        best = int(np.argmin(D2.mean(1)))\n",
    "        med[int(cls)] = Xc[idx[best]:idx[best]+1]\n",
    "    return med\n",
    "\n",
    "def pick_opposite_medoid(x_raw, clf_phi, medoids, transform_prime):\n",
    "    phi_x = transform_prime(x_raw)[\"phi\"]\n",
    "    proba = clf_phi.predict_proba(phi_x)[0]\n",
    "    classes = clf_phi.classes_\n",
    "    order = np.argsort(-proba)\n",
    "    y_hat = int(classes[order[0]])\n",
    "    for j in order[1:]:\n",
    "        cand = int(classes[j])\n",
    "        if cand in medoids:\n",
    "            return medoids[cand], cand\n",
    "    for cand in medoids:\n",
    "        if cand != y_hat:\n",
    "            return medoids[cand], cand\n",
    "    raise RuntimeError(\"No hay medoid opuesto disponible.\")\n",
    "\n",
    "\n",
    "if BASELINE_FROM == \"train\":\n",
    "    X_base, y_base = X_train, y_train\n",
    "else:\n",
    "    X_base, y_base = X, y\n",
    "medoids = compute_medoids_by_class(X_base, y_base, max_candidates=300)\n",
    "\n",
    "\n",
    "if RUN_SCOPE == \"test\":\n",
    "    X_run, y_run = X_test, y_test\n",
    "    split_tag = \"test\"\n",
    "else:\n",
    "    X_run, y_run = X, y\n",
    "    split_tag = \"all\"\n",
    "\n",
    "\n",
    "F = mmv.transform_prime(X_run[0:1])[\"phi\"].shape[1]\n",
    "T = X_run.shape[2]\n",
    "N = len(X_run)\n",
    "\n",
    "betas_path        = os.path.join(OUT_DIR, f\"betas_{split_tag}.mmap\")\n",
    "alphas_shap_path  = os.path.join(OUT_DIR, f\"alphas_shap_raw_{split_tag}.mmap\")\n",
    "alphas_cal_path   = os.path.join(OUT_DIR, f\"alphas_shap_cal_{split_tag}.mmap\")\n",
    "\n",
    "betas_mm       = np.memmap(betas_path,       dtype=\"float32\", mode=\"w+\", shape=(N, T))\n",
    "alphas_shap_mm = np.memmap(alphas_shap_path, dtype=\"float32\", mode=\"w+\", shape=(N, F))\n",
    "alphas_cal_mm  = np.memmap(alphas_cal_path,  dtype=\"float32\", mode=\"w+\", shape=(N, F))\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in tqdm(range(N), desc=f\"Exportando (SHAP only) [{split_tag}]\"):\n",
    "    x_raw = X_run[i:i+1]\n",
    "    x_tc  = x_raw[0].T\n",
    "\n",
    "    # Baseline = medoid opuesto\n",
    "    X0_op, cls_opp = pick_opposite_medoid(x_raw, clf_phi, medoids, mmv.transform_prime)\n",
    "    x0_tc = X0_op[0].T\n",
    "\n",
    "    # Δf (logits)\n",
    "    fx  = float(mmv.model_logit(x_tc))\n",
    "    fx0 = float(mmv.model_logit(x0_tc))\n",
    "    delta_f = fx - fx0\n",
    "\n",
    "    # ϕ y trazas\n",
    "    out_x   = mmv.transform_prime(x_raw)\n",
    "    out_x0  = mmv.transform_prime(X0_op)\n",
    "    phi_x   = out_x[\"phi\"]\n",
    "    phi_x0  = out_x0[\"phi\"]\n",
    "    traces  = out_x[\"traces\"]\n",
    "    traces0 = out_x0[\"traces\"]\n",
    "\n",
    "    # α SHAP en ϕ_scaled\n",
    "    phi_x_scaled  = scaler.transform(phi_x)\n",
    "    phi_x0_scaled = scaler.transform(phi_x0)\n",
    "\n",
    "    proba   = clf_phi.predict_proba(phi_x)[0]\n",
    "    cls_idx = int(np.argmax(proba))\n",
    "\n",
    "    sv = explainer.shap_values(phi_x_scaled)  # robusto a versiones\n",
    "    if isinstance(sv, list):\n",
    "        alphas_shap_raw = sv[cls_idx][0]          # (F,)\n",
    "    else:\n",
    " \n",
    "        alphas_shap_raw = sv[0] if cls_idx == 1 else -sv[0]\n",
    "\n",
    "\n",
    "    alphas_shap_cal = mmv.calibrate_alphas_to_delta_f(\n",
    "        alphas_shap_raw, delta_f, phi_x_scaled, phi_x0_scaled\n",
    "    )\n",
    "\n",
    "    sigma_ref = [tr0[\"sigma\"] for tr0 in traces0]\n",
    "    beta = mmv.propagate_luis(alphas_shap_cal, traces, x_tc, x0_tc, sigma_ref=sigma_ref)\n",
    "\n",
    "    betas_mm[i, :]       = (beta[:,0] if beta.ndim==2 else beta.ravel()).astype(np.float32)\n",
    "    alphas_shap_mm[i, :] = alphas_shap_raw.astype(np.float32)\n",
    "    alphas_cal_mm[i, :]  = alphas_shap_cal.astype(np.float32)\n",
    "\n",
    "    rows.append({\n",
    "        \"i\": i,\n",
    "        \"y_true\": int(y_run[i]),\n",
    "        \"y_opp_used\": int(cls_opp),\n",
    "        \"delta_f\": float(delta_f),\n",
    "        \"sum_alpha_shap_cal\": float(np.sum(alphas_shap_cal)),\n",
    "        \"sum_beta\": float(beta.sum()),\n",
    "        \"error\": float(beta.sum() - delta_f)\n",
    "    })\n",
    "\n",
    "\n",
    "del betas_mm, alphas_shap_mm, alphas_cal_mm\n",
    "\n",
    "df_eff = pd.DataFrame(rows)\n",
    "df_eff[\"rel_error\"] = (df_eff[\"error\"].abs()/(df_eff[\"delta_f\"].abs()+1e-12))\n",
    "df_eff.to_csv(os.path.join(OUT_DIR, f\"efficiency_{split_tag}.csv\"), index=False)\n",
    "\n",
    "print(f\"Listo. Exportado en '{OUT_DIR}':\")\n",
    "print(f\"  - {os.path.basename(betas_path)}         (β; shape=({N},{T}))\")\n",
    "print(f\"  - {os.path.basename(alphas_shap_path)}   (α SHAP raw; shape=({N},{F}))\")\n",
    "print(f\"  - {os.path.basename(alphas_cal_path)}    (α SHAP calibrados; shape=({N},{F}))\")\n",
    "print(f\"  - efficiency_{split_tag}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ef2c6-95af-46d7-a5a5-2fec4c8d7479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
